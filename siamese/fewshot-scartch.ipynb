{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "255165cc-d74a-4183-b087-8a7872b4dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import data\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "938e57fa-1541-49cd-9e70-ebda2d0da45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data' from '/Users/deepakduggirala/Documents/project/siamese/data.py'>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc2ecfc7-75f8-475d-9917-7158780b30b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/deepakduggirala/Documents/Elephants-dataset-cropped-png-1024/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d04ad32-e2fa-4702-88e4-eeccdb7185d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'image_size': 256,\n",
    "    'resize_pad': False,\n",
    "    'dense_l2_reg_c': 0.0001,\n",
    "    'embedding_size': 17,\n",
    "    'lr': 0.001\n",
    "}\n",
    "\n",
    "cache_files = {\n",
    "        'train': str(Path(data_dir) / 'train.cache'),\n",
    "        'val': str(Path(data_dir) / 'val.cache')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "460e1ab7-6051-4af9-a137-dea1cef81051",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths, image_labels = data.get_zoo_elephants_images_and_labels(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "463e7a3b-8f66-411f-ba34-4b73ca950ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(n):\n",
    "    x = np.arange(n, dtype=np.int32)\n",
    "    np.random.shuffle(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a5116860-67c4-4504-a2fe-f31871c96199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_support_and_query_sets(image_paths, image_labels, n_support):\n",
    "    support_images = []\n",
    "    support_labels = []\n",
    "\n",
    "    query_images = []\n",
    "    query_labels = []\n",
    "    \n",
    "    np.random.seed(99)\n",
    "    counts = Counter(image_labels)\n",
    "    shuffled_idxs = {c:shuffle(count) for c, count in counts.items()}\n",
    "    \n",
    "    for c, idxs in shuffled_idxs.items():\n",
    "        s_idxs = idxs[:n_support]\n",
    "        q_idxs = idxs[n_support:]\n",
    "\n",
    "        mask = np.array(image_labels)==c\n",
    "        c_image_labels = np.array(image_labels)[mask]\n",
    "        c_image_paths = np.array(image_paths)[mask]\n",
    "\n",
    "        support_images.extend(c_image_paths[s_idxs]) \n",
    "        support_labels.extend(c_image_labels[s_idxs])\n",
    "        query_images.extend(c_image_paths[q_idxs])\n",
    "        query_labels.extend(c_image_labels[q_idxs])\n",
    "        \n",
    "    return support_images, support_labels, query_images, query_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9248a474-2c5f-480e-bd97-93780da731b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, support_ds):\n",
    "    preds = base_model.predict(support_ds, verbose=True)\n",
    "    return preds/np.linalg.norm(preds, axis=1, keepdims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "e0480301-7818-4b79-8f9f-99a1402f5a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_support_class_means(preds, categories, support_labels):\n",
    "    class_means = np.zeros((17, 2048))\n",
    "    for i,c in enumerate(categories):\n",
    "        mask = np.array(support_labels) == c\n",
    "        class_means[i,:] = np.mean(preds[mask, :], axis=0)\n",
    "    return class_means.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c7c82c3a-a189-421b-8973-936989f039d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "support_images, support_labels, query_images, query_labels = get_support_and_query_sets(\n",
    "    image_paths, image_labels, n_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "8faf801d-27b3-470b-a23d-c00e9742c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"image_size\": 256,\n",
    "    \"resize_pad\": False,\n",
    "    \"batch_size\": {\n",
    "      \"support\": 32,\n",
    "      \"query\": 32,\n",
    "      },\n",
    "    \"lr\": 0.00005,\n",
    "  \"decay_steps\": 13,\n",
    "  \"decay_rate\": 0.96,\n",
    "  \"dense_l2_reg_c\": 0.01,\n",
    "  'embedding_size': 17\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "838fe490-735b-4926-999b-3d0015564642",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.ResNet50V2(include_top=False, weights=\"imagenet\", input_shape=(\n",
    "        params['image_size'], params['image_size'], 3), pooling='avg')\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "\n",
    "inputs = tf.keras.Input(shape=(params['image_size'], params['image_size'], 3))\n",
    "\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "# dense1 = tf.keras.layers.Dense(units=17, activation='softmax', name='dense1')(x)\n",
    "custom_layer = CustomLayer(w_init=W.T, units=17, input_dim=2048)(x)\n",
    "model = tf.keras.Model(inputs, custom_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "65ac6a82-47f8-4691-8250-82a0f1b53559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'resnet50v2'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "a87433dc-7d04-4bae-92d2-49bd3e056b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_20 (InputLayer)       [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      " custom_layer_2 (CustomLayer  (None, 17)               34833     \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,599,633\n",
      "Trainable params: 34,833\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "d06b8e48-9ada-43b0-a3fd-77e2ac65b709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore', sparse=False)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "enc.fit(np.array(support_labels).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "3d56b277-1859-4d1f-aa97-172244b284ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 4s 954ms/step\n"
     ]
    }
   ],
   "source": [
    "support_ds, _, _ = get_dataset(support_images, support_labels,\n",
    "                                       params,\n",
    "                                       augment=False,\n",
    "                                       cache_file=None,\n",
    "                                       shuffle=False,\n",
    "                                       batch_size=params['batch_size']['support'])\n",
    "\n",
    "preds = get_preds(base_model, support_ds)\n",
    "W = get_support_class_means(preds, enc.categories_[0], support_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef72ec88-9cf2-4efe-aff0-361bdf7d6b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = enc.transform(np.array(query_labels).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "815f554d-d662-4a58-90f9-92b975df6276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534415ba-8c50-4796-aed7-a160a572fb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d257ffe6-12bd-47e0-92ad-6fb8ee41d23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, image_size, augment=True, model_preprocess=True):\n",
    "    if augment:\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        # image = tf.image.random_brightness(image, 0.2)\n",
    "        # image = tf.image.random_contrast(image, 0.5, 2.0)\n",
    "        image = tf.image.random_saturation(image, 0.75, 1.25)\n",
    "        image = tf.image.random_hue(image, 0.05)\n",
    "        # image = tf.image.random_jpeg_quality(image, 20, 100)\n",
    "    if model_preprocess:\n",
    "        image = preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def parse_image_function(image_path, image_size, resize_pad=False):\n",
    "    # print('reading', image_path)\n",
    "    image_string = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    if not resize_pad:\n",
    "        image = tf.image.resize(image, [image_size, image_size])\n",
    "    else:\n",
    "        image = tf.image.resize_with_pad(image, target_height=image_size, target_width=image_size)\n",
    "    # image = preprocess_image(image, image_size, augment)\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_dataset(image_paths, image_labels, params,\n",
    "                augment=None, cache_file=None, model_preprocess=True,\n",
    "                shuffle=True, batch_size=32):\n",
    "    N = len(image_labels)\n",
    "\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, image_labels))\n",
    "    dataset = dataset.map(lambda x, y: (parse_image_function(\n",
    "        x, params['image_size'], resize_pad=params['resize_pad']), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    if cache_file:\n",
    "        dataset = dataset.cache(cache_file)\n",
    "\n",
    "    dataset = dataset.map(lambda x, y: (\n",
    "        preprocess_image(x, params['image_size'], augment=augment, model_preprocess=model_preprocess), y),\n",
    "        num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=N)\n",
    "\n",
    "    if batch_size:\n",
    "        dataset = dataset.batch(batch_size).prefetch(AUTOTUNE)\n",
    "\n",
    "    return dataset, N, image_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e977a15-639c-4da7-9d18-114fc4481c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f8b607-7550-4ef0-80a0-cf0c760188c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dca1141-d6e1-4109-8eac-8a3ff2a1e5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244c4d90-4545-4e3d-ac9f-cd01b698ddfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b5f89661-369b-4f13-9a3f-9dfbb81f1207",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "labels = enc.fit_transform(np.array(image_labels).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3d4856f0-bd66-4bbe-815d-bcc9bfc1b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=99)\n",
    "sss.get_n_splits(image_paths, labels)\n",
    "train_index, test_index = next(sss.split(image_paths, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3b608806-7a02-40bf-95cb-b8e47023ccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss_fn(y_true, y_pred, C=0.1):\n",
    "    # tf.print(y_pred.shape)\n",
    "    cross_entropy_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "    entropy_loss = -tf.reduce_sum(y_pred * tf.math.log(y_pred), 1)\n",
    "    return cross_entropy_loss + C * entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8b827b68-06b0-436e-bf00-951c4406b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001), \n",
    "    loss=my_loss_fn,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e6b03bee-6bd9-4b3c-bd80-6d03c5d1bb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step - loss: 3.0601 - accuracy: 0.1250 - val_loss: 3.0481 - val_accuracy: 0.0938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16675bd60>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds.take(1), epochs=1, validation_data=val_ds.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "4d713d1f-7c57-4b69-a2e9-cc336a6958e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, w_init, units=17, input_dim=2048):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        self.w = tf.Variable(\n",
    "            initial_value=w_init,\n",
    "            trainable=True,\n",
    "        )\n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.b = tf.Variable(\n",
    "            initial_value=b_init(shape=(units,), dtype=\"float32\"), trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        embeddings = tf.math.l2_normalize(inputs, axis=1, epsilon=1e-10) # b x 2048, w: 2048 x 17\n",
    "        t = tf.matmul(embeddings, self.w)                                # b x 17\n",
    "        t = tf.math.l2_normalize(t, axis=1, epsilon=1e-10)\n",
    "        z = t + self.b\n",
    "        return tf.keras.activations.softmax(z, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3efaff-2947-4d7a-8e9e-178536ce4411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "added8e2-f8e1-4e72-8c2c-3db7b8a687c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c9bb43-442b-4a2a-b683-41da3787e447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
