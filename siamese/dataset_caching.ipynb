{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6df89a07-f65c-458b-83a2-40e8b9ebdbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from data import get_dataset, get_zoo_elephants_images_and_labels, get_ELEP_images_and_labels, parse_image_function\n",
    "from train import SiameseModel\n",
    "\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2683d30-3704-4f46-bc03-aef313e1c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hyperparameters/initial_run.json', 'rb') as f:\n",
    "    params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c07866ac-87d1-4805-b829-3581ba597e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/deepakduggirala/Documents/ELPephant-cropped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b110c3ea-fb59-48e1-97ec-99853b1668bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_files = {\n",
    "        'train': str(Path(data_dir) / 'train.cache'),\n",
    "        'val': str(Path(data_dir) / 'val.cache')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65c38b51-c4a6-4e42-b234-3ae23a5450a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode = 'train'\n",
    "# image_paths, image_labels = get_ELEP_images_and_labels(Path(data_dir)/mode)\n",
    "# N = len(image_labels)\n",
    "\n",
    "# AUTOTUNE = tf.data.AUTOTUNE\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((image_paths, image_labels))\n",
    "# dataset = dataset.shuffle(buffer_size=N)\n",
    "# dataset = dataset.map(lambda x, y: (parse_image_function(\n",
    "#         x, params['image_size']), y), num_parallel_calls=AUTOTUNE)\n",
    "# dataset = dataset.cache(cache_files[mode])\n",
    "# dataset = dataset.batch(params['batch_size']).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d9f9148-8e35-401d-a5bc-068593c6d7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading Tensor(\"args_0:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "train_ds, _, N_train = get_dataset(get_ELEP_images_and_labels, params, data_dir, 'train', cache_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "549d8771-1afb-4b4b-97ef-ea9eaa9dbdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-22 02:10:18.568194: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-22 02:10:28.587355: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 1061 of 1618\n",
      "2022-04-22 02:10:34.335349: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:405] Shuffle buffer filled.\n",
      "2022-04-22 02:10:34.411569: W tensorflow/core/kernels/data/cache_dataset_ops.cc:233] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (128,)\n",
      "new labels 89\n",
      "1 (128,)\n",
      "new labels 43\n",
      "2 (128,)\n",
      "new labels 35\n",
      "3 (128,)\n",
      "new labels 19\n",
      "4 (128,)\n",
      "new labels 15\n",
      "5 (128,)\n",
      "new labels 7\n",
      "6 (128,)\n",
      "new labels 3\n",
      "7 (128,)\n",
      "new labels 1\n",
      "8 (128,)\n",
      "new labels 2\n",
      "9 (128,)\n",
      "new labels 0\n",
      "10 (128,)\n",
      "new labels 0\n",
      "11 (128,)\n",
      "new labels 0\n",
      "12 (82,)\n",
      "new labels 0\n",
      "CPU times: user 30.2 s, sys: 3.02 s, total: 33.2 s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "s = set()\n",
    "i=0\n",
    "for images, labels in train_ds.as_numpy_iterator():\n",
    "    print(i, labels.shape)\n",
    "    print('new labels', len(set(labels)-s))\n",
    "    s.update(set(labels))\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "491651d4-0689-4a90-b1a5-393bb20166bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900d6f01-f0b5-45da-8c0c-5700183186cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10a39851-6c33-410b-bc80-30f66e017288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading Tensor(\"args_0:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "val_ds, _, N_val = get_dataset(get_ELEP_images_and_labels, params, data_dir, 'val', cache_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "739716f2-0c2f-452e-a23e-228e1dd2911b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = next(val_ds.as_numpy_iterator())\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec406557-c2f7-4ce2-b706-3309409afeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5d4678-262e-4696-9b9b-cc9ed00d49de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720878a8-e63b-4fa5-9a4b-7768ed57b26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "293b1b94-f362-4a8b-8e67-4058085db6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading Tensor(\"args_0:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "mode = 'train'\n",
    "image_paths, image_labels = get_ELEP_images_and_labels(Path(data_dir)/mode)\n",
    "N = len(image_labels)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_paths, image_labels))\n",
    "# dataset = dataset.shuffle(buffer_size=N)\n",
    "dataset = dataset.map(lambda x, y: (parse_image_function(\n",
    "        x, params['image_size']), y), num_parallel_calls=AUTOTUNE)\n",
    "dataset = dataset.cache(cache_files[mode])\n",
    "dataset = dataset.shuffle(buffer_size=N)\n",
    "dataset = dataset.batch(params['batch_size']).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2176843-3a66-42b5-b2b9-2202a9383989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'1578', b'2559', b'3898', b'4249', b'3470', b'2350', b'2655',\n",
       "       b'264', b'4169', b'3746', b'2090', b'638', b'2651', b'4246',\n",
       "       b'2674', b'3012', b'3897', b'1732', b'1437', b'1319', b'1997',\n",
       "       b'3999', b'951', b'52', b'3372', b'3898', b'1009', b'1211',\n",
       "       b'2353', b'3412', b'1287', b'1123', b'3441', b'3012', b'637',\n",
       "       b'3252', b'1566', b'1566', b'183', b'2651', b'2559', b'1888',\n",
       "       b'373', b'2241', b'3409', b'42', b'568', b'5160', b'2841', b'1319',\n",
       "       b'3346', b'15', b'3252', b'373', b'1876', b'4031', b'2350',\n",
       "       b'2380', b'520', b'520', b'3470', b'1436', b'2723', b'1234',\n",
       "       b'843', b'1186', b'3410', b'3384', b'1123', b'565', b'2779',\n",
       "       b'3898', b'3999', b'1577', b'654', b'251', b'3410', b'3746',\n",
       "       b'1370', b'459', b'3809', b'3901', b'1411', b'1439', b'5259',\n",
       "       b'284', b'3766', b'4031', b'15', b'2602', b'567', b'818', b'145',\n",
       "       b'3062', b'1673', b'2651', b'4031', b'4109', b'5137', b'2380',\n",
       "       b'3756', b'3346', b'3550', b'520', b'1365', b'637', b'1548',\n",
       "       b'2844', b'3898', b'4084', b'1436', b'1074', b'611', b'3999',\n",
       "       b'35', b'5137', b'1997', b'1945', b'1319', b'3055', b'1411',\n",
       "       b'1536', b'637', b'1086', b'183', b'1576', b'373', b'3747'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = next(dataset.as_numpy_iterator())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f995e857-c320-4475-b792-6d4038b7e7b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb09412-3cf4-4043-8fe4-cc3fb5eede7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9782a7-249e-4d8c-88b6-8632cec83f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db363ce2-1d0f-4c7a-88dd-31abdefdd98c",
   "metadata": {},
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b75ffe-e356-4a62-96a2-55c6e4c119c2",
   "metadata": {},
   "source": [
    "ids = np.arange(274)\n",
    "np.random.shuffle(ids)\n",
    "val_ids = ids[:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a59dc4d-886d-4bbb-9324-0b860907f26f",
   "metadata": {},
   "source": [
    "sorted_unique_labels = sorted(set(image_labels))\n",
    "c = Counter(sorted(image_labels))\n",
    "sum([c[sorted_unique_labels[i]] for i in val_ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24603650-7487-4a3b-b909-279a5ee460e0",
   "metadata": {},
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f317736c-3b2a-4881-ad66-d0a706cff468",
   "metadata": {},
   "source": [
    "val_dir = Path(data_dir) / 'val'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ad31a-5b0b-4e52-949f-c2b8d12b5ed7",
   "metadata": {},
   "source": [
    "val_class_ids = [sorted_unique_labels[i] for i in val_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874b8c16-ab16-41d6-984e-4b9066104a6d",
   "metadata": {},
   "source": [
    "val_files = [i for i in Path(data_dir).iterdir() if i.suffix in ['.jpg'] and i.name.split('_')[0] in val_class_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbde1bb0-11dc-42c4-ac61-24fb4fa17e7c",
   "metadata": {},
   "source": [
    "len(val_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5b902b-058a-43a6-a191-03979274ff13",
   "metadata": {},
   "source": [
    "val_dir.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aec57e0-4c89-47b1-8f93-fb6931481c81",
   "metadata": {},
   "source": [
    "for src in val_files:\n",
    "    target = val_dir / src.name\n",
    "    src.replace(target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
